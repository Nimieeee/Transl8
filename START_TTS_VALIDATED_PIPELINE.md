# Start TTS-Validated Pipeline - Complete Guide

## Quick Start (3 Terminals Required)

### Terminal 1: Backend
```bash
cd packages/backend
npm run dev
```
**Wait for:** `Server listening on port 3001`

### Terminal 2: Workers
```bash
cd packages/workers
npm run dev
```
**Wait for all 5 workers:**
- âœ“ STT Worker started (OpenAI Whisper)
- âœ“ Adaptation Worker started (Mistral AI) â† **TTS validation happens here**
- âœ“ TTS Worker started (OpenAI TTS)
- âœ“ Final Assembly Worker started
- âœ“ Muxing Worker started

### Terminal 3: Upload Video
```bash
curl -X POST http://localhost:3001/api/dub/upload \
  -F "video=@test-video.mov" \
  -F "targetLanguage=es"
```

---

## What You'll See

### In Terminal 2 (Workers), watch for:

```
ğŸ¯ TTS-validating 2 segments
Using TTS-validated adaptation (Â±15% tolerance)

ğŸ“ TTS-validating segment 0/2: "Hi, my name is..." (10.2s)
ğŸ”„ Starting TTS-validated adaptation for segment 0
   Target duration: 10.24s (Â±15%)
ğŸ“ Attempt 1/3
   Generated text: "Hola, soy Tolu y esto es una demo..."
   ğŸ¤ Generating test audio...
   Actual duration: 10.15s
   âœ… WITHIN TOLERANCE (10.15s vs 10.24s, -0.9% diff)
   âœ… SUCCESS: "Hola, soy Tolu..." (10.15s, 1 attempts)

ğŸ“Š TTS-VALIDATED ADAPTATION SUMMARY
Total segments: 2
Successful: 2 (100%)
Average attempts: 1.0
Total TTS calls: 2

ğŸš€ TTS-validated adaptation complete (100% success)
```

---

## The TTS-Validated Loop is READY

âœ… All code implemented and verified
âœ… Bug fixed (OpenAI TTS API parameters)
âœ… 12 comprehensive documentation files created
âœ… Integration confirmed

**Just start the services and watch it work!** ğŸš€
